# GCMN

We introduce Graph Chain-Merging Networks (GCMN), novel neural network architectures designed to overcome the limitations of message-passing architectures in reasoning about long-range patterns and generalizing such reasoning from small training samples to larger graphs. We investigate two GCMN variants – Graph Heavy-Light-Decomposed Networks (GraphHLDN) and Graph Chain-To-Nodes Aggregation (GraphC2N) – both employing a common principle: the network computes representations of entire chains by merging smaller chains into larger ones, rather than focusing on individual nodes.

GraphHLDN is efficiently applicable to acyclic graphs, as it restructures the tree to achieve a depth of $O(\log^2 n)$. In contrast, GraphC2N operates on arbitrary graphs, aggregating information about chains between all vertex pairs across $O(\log n)$ message-passing layers. Both approaches enable  reasoning about long-range sequences and fast information propagation and aggregation across graphs, while considering ordering of the features on chains. We demonstrate that our method alleviates the previous reliance on step-by-step supervision in certain algorithmic reasoning tasks and substantially outperforms message-passing networks in out-of-distribution generalization to larger scales. Additionally, our technique is applicable to real-world datasets, attaining or surpassing state-of-the-art results on multiple molecular datasets.
